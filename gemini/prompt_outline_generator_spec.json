[
	{
		"prompt_id": "outline_generator_prompt",
		"description": "Generates the natural language prompt instruction for the LLM that will produce the prompt outline.",
		"after": [],
		"prompt_content": "Generate a natural language prompt for an LLM. This prompt should instruct the LLM to act as an 'Expert Software Architect'. It needs to take a user's high-level software description and decompose it into a set of 'promptable components'. For each component, it should identify a unique `prompt_id` (snake_case), a concise `description` (its intent), its `output_format` (choosing from 'python', 'markdown', 'json', 'text'), **and a `prompt_content` field. For the `prompt_content`, provide a placeholder string like 'TODO: Implement [description of this component]. Be very specific in your full prompt for this component.'.** Also include an `after` array listing any `prompt_id`s it logically depends on. The LLM should be told to output this as a JSON array of objects, conforming strictly to the structure: `[{ 'prompt_id': '...', 'description': '...', 'after': ['...'], 'output_format': '...', 'prompt_content': '...' }]`. CRITICAL: The output MUST contain ONLY the valid JSON array. Do NOT include any introductory text, extra words, code block delimiters (e.g., ```json), or any other extraneous characters before or after the JSON array. The generated prompt should start with 'You are an Expert Software Architect. Your task is to decompose a user's high-level software description into a structured outline of promptable components...'. It should emphasize strict adherence to the JSON format. Do not include example JSON output in the generated prompt, only the instructions for the LLM.",
		"output_format": "text",
		"model": "gemini-1.5-pro-latest",
		"temperature": 0.3
	},
		{
		"prompt_id": "outline_generator_script",
		"description": "Generates a Python script that takes a user description, uses the generated prompt to call an LLM (e.g., Google Gemini API), and outputs the raw JSON response.",
		"after": ["outline_generator_prompt"],
		"prompt_content": "Generate a Python script named `outline_generator_script.py`. This script should: \n1. Take a single command-line argument: the high-level software description string from the user. \n2. Read the content of the `outline_generator_prompt.txt` file (which will be in the same directory as this script) into a Python variable named `GENERATOR_PROMPT_INSTRUCTION`. This is crucial for avoiding Python string literal issues. \n3. Make an API call to a large language model (e.g., Google's `gemini-1.5-pro-latest` via `google.generativeai.GenerativeModel().generate_content`). **Ensure you pass the full prompt string as the FIRST POSITIONAL ARGUMENT to `generate_content`, without using a keyword like 'prompt='. Example: `model.generate_content(your_full_prompt_string, generation_config=...)`.**\n4. The user's software description should be incorporated into the `GENERATOR_PROMPT_INSTRUCTION` as the input to the LLM. For example, append 'The software to design is: \"[user's description]\"' to the instruction. \n5. Print the raw JSON response from the LLM to standard output. \n6. Include necessary imports (e.g., `os`, `sys`, `json`, `google.generativeai`). \n7. Initialize the Google Generative AI client by calling `google.generativeai.configure(api_key=os.environ.get('GEMINI_API_KEY'))` at the beginning of the script. Do NOT pass 'api_key' directly to the `GenerativeModel` constructor or `generate_content` method, as `genai.configure` handles global API key setup. \n8. Handle potential API key issues (e.g., `GEMINI_API_KEY` environment variable). \n9. Ensure it's executable via `if __name__ == '__main__':`. \n\nFocus solely on the script logic; do not include example usage in the output, just the functional script.",
		"output_format": "python",
		"model": "gemini-1.5-pro-latest",
		"temperature": 0.5
	},
	{
  "prompt_id": "test_outline_generation",
  "description": "Generates a Python script to test the `outline_generator_script.py` script with a sample input, validating its output format.",
  "after": ["outline_generator_script"],
  "prompt_content": "Generate a Python script named `test_generate_outline.py`. This script should: \n1. Define a sample high-level software description, e.g., 'A simple command-line tool to convert temperatures between Celsius and Fahrenheit.'\n2. Get the directory of the current script (`test_generate_outline.py`) using `script_dir = os.path.dirname(os.path.abspath(__file__))`.\n3. **Construct the full, absolute path to the `outline_generator_script.py` script. It will be in the same directory. Use `target_script_path = os.path.join(script_dir, 'outline_generator_script.py')`.**\n4. Call `outline_generator_script.py` as a subprocess using `subprocess.run`. The command arguments for `subprocess.run` MUST be a list where:\n    a. The first element is the path to the Python interpreter: `sys.executable`.\n    b. The second element is the FULL, ABSOLUTE path to the script to execute: `target_script_path`.\n    c. The third element is the sample high-level software description string.\n   Ensure `check=True` (to raise an error on non-zero exit), `capture_output=True`, and `text=True` are used in `subprocess.run`.**\n5. Capture its standard output (`result.stdout`). \n6. Attempt to parse the captured output as JSON. \n7. Assert that the parsed JSON is a list (array) and that each item in the list is an object containing at least the keys 'prompt_id', 'description', 'after', and 'output_format'. \n8. Print 'Test passed!' or 'Test failed!' based on the assertions. Include helpful error messages if it fails. \n9. Include necessary imports: `subprocess`, `json`, `sys`, `os`. \n\nEnsure this is a runnable test script and it handles file paths for subprocess execution with absolute clarity and robustness, providing the full path to the script being run.",
  "output_format": "python",
  "model": "gemini-1.5-pro-latest",
  "temperature": 0.6
}
]
